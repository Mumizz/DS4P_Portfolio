---
title: "Portfolio 2: Exploring Eye-tracking Data in Reading"
subtitle: "Analysis of the OneStop Eye Movements Dataset"
author: "Barbara Mu" 
date: "Jan 29, 2026"
---

> The projects should be numbered consecutively (i.e., in the order in which you began them), and should include for each project a description of the goal, the product (computer program, hand graph, computer graph, etc.), the data, and some interpretation. Reports must be reproducible and of high quality in terms of writing, grammar, presentation, etc.

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.width = 10,
  fig.height = 6,
  fig.align = "center"
)
```


---

# Background

Eye movements during reading provide a window into real-time cognitive processing. When we read, our eyes make rapid movements (saccades) and brief pauses (fixations). The duration of fixations and the probability of skipping words reveal how factors like word length, frequency, and predictability influence visual attention allocation (Rayner, 1998, 2009).

## Data

This analysis uses the OneStop Eye Movements Dataset (Berzak et al., 2025), a large-scale corpus containing 360 participants reading news articles with eye-tracking measures. It also includes rich lexical annotations, such as word frequency, GPT-2 surprisal, and part-of-speech tags. 

# Goal

The goal of this portfolio is to explore eye-tracking data from a reading study and investigate how word length and word frequency interact to influence reading behavior. Specifically, this portfolio:

1. Explores and visualizes eye-tracking data during reading, demonstrating key phenomena documented in the psycholinguistics literature (e.g., effects of word length, frequency, predictability, and part of speech on fixation duration and skipping)

2. Investigates whether the effect of word length on fixation duration differ for high-frequency vs. low-frequency words? This analysis tests the hypothesis that word length effects are stronger for unfamiliar (low-frequency) words, consistent with dual-route models of word recognition.


---

# Setup
```{r}
# Load packages
library(tidyverse)   
library(scales)     
library(patchwork)  
library(knitr) 
```


```{r}
# Load data 
ia <- read_csv("~/Desktop/2025-2026/Courses/Data science for psych/Portfolio 1/ia_Paragraph_ordinary.csv")
```



# Data Exploration

## Data Structure

### Data Overview
```{r}
# Basic dimensions
cat("Interest Area dataset dimensions:", dim(ia)[1], "rows x", dim(ia)[2], "columns\n")

# Check key eye-tracking measures
ia %>%
  select(IA_FIRST_FIXATION_DURATION, IA_FIRST_RUN_DWELL_TIME,
         IA_DWELL_TIME, IA_FIXATION_COUNT, IA_SKIP) %>%
  summary()
```

The dataset contains over 1 million word-level observations with 157 variables. The summary statistics show that eye-tracking measures are stored as character type, which will need conversion to numeric during cleaning. The `IA_SKIP` variable is binary (0/1), indicating whether each word was skipped during reading.

### Key Variables for Analysis

#### Dependent Variables: Eye-tracking Measures

The data contains word-level reading measures that are central to eye-tracking research:

| Measure | Description | Type |
|---------|-------------|------|
| `IA_FIRST_FIXATION_DURATION` | Duration of first fixation on word (ms) | Early measure |
| `IA_FIRST_RUN_DWELL_TIME` | Gaze duration: total time on word before leaving (ms) | Early measure |
| `IA_DWELL_TIME` | Total reading time on word across all visits (ms) | Late measure |
| `IA_SKIP` | Whether the word was skipped (0 = fixated, 1 = skipped) | Binary |
| `IA_REGRESSION_IN` | Whether reader regressed back to this word | Late measure |
| `IA_REGRESSION_OUT` | Whether reader regressed from this word | Late measure |

**Early vs. Late measures:** Early measures (FFD, Gaze Duration) reflect initial word processing, while late measures (Total Time, Regressions) reflect re-reading and integration difficulties.

#### Independent Variables: Lexical Predictors

The dataset includes lexical properties for each word that are known to influence reading:

| Variable | Description | Expected Effect |
|----------|-------------|-----------------|
| `word_length` | Number of characters in the word | Longer words → longer fixations, fewer skips |
| `wordfreq_frequency` | How common the word is in everyday language (from wordfreq corpus) | Higher frequency → shorter fixations, more skips |
| `gpt2_surprisal` | How predictable the word is given prior context (from GPT-2 language model) | Higher surprisal (less predictable) → longer fixations |
| `Reduced_POS` | Part of speech category (ADJ, FUNC, NOUN, VERB, UNKNOWN) | Function words processed faster than content words |

**Word frequency** reflects how often a word appears in written/spoken language. Common words like "the" and "is" have high frequency, while rare words like "ubiquitous" have low frequency. Frequent words are processed faster because readers have stronger memory representations for them.

**Surprisal** measures how unexpected a word is given its context. For example, in "The dog chased the ___", "cat" has low surprisal (predictable) while "helicopter" has high surprisal (unexpected). GPT-2, a neural language model, computes surprisal as the negative log probability of the word.

```{r}
# Examine lexical predictors available
ia %>%
  select(word_length, word_length_no_punctuation,
         wordfreq_frequency, subtlex_frequency,
         gpt2_surprisal, Reduced_POS) %>%
  summary()
```

**Interpretation:**

- **Word length** ranges from 1-20+ characters, with a median around 4-5 characters (typical for English text)
- **Word frequency** values are on a logarithmic scale; higher values indicate more frequent words
- **GPT-2 surprisal** ranges from near 0 (highly predictable) to 30+ (very unexpected)
- **Reduced_POS** includes 5 categories: adjectives (ADJ), function words (FUNC), nouns (NOUN), verbs (VERB), and unknown (UNKNOWN)

---

# Data Cleaning

## Remove Practice Trials and Problematic Data

```{r}
# Check for practice trials
table(ia$practice_trial)
```

**Interpretation:** The dataset contains both practice trials (TRUE) and experimental trials (FALSE). Practice trials are used for participants to familiarize themselves with the task and should be excluded from analysis to ensure data quality.

```{r warning=FALSE, message=FALSE}
ia_clean <- ia %>%
  mutate(
    IA_FIRST_FIXATION_DURATION = as.numeric(IA_FIRST_FIXATION_DURATION),
    IA_FIRST_RUN_DWELL_TIME = as.numeric(IA_FIRST_RUN_DWELL_TIME),
    IA_DWELL_TIME = as.numeric(IA_DWELL_TIME),
    IA_FIXATION_COUNT = as.numeric(IA_FIXATION_COUNT)
  )
```
```{r}
ia_clean <- ia_clean %>%
  filter(practice_trial == FALSE, 
         repeated_reading_trial == FALSE,
         !is.na(IA_FIRST_FIXATION_DURATION), 
         IA_FIRST_FIXATION_DURATION >= 80 & IA_FIRST_FIXATION_DURATION <= 800)
```

## Check Distribution of Key Variables

```{r warning=FALSE, message=FALSE, fig.height=8}
# Distribution of key reading measures
p1 <- ggplot(ia_clean, aes(x = IA_FIRST_FIXATION_DURATION)) +
  geom_histogram(bins = 50, fill = "steelblue", alpha = 0.7) +
  labs(title = "First Fixation Duration", x = "Duration (ms)", y = "Count") +
  theme_minimal()

p2 <- ggplot(ia_clean, aes(x = IA_FIRST_RUN_DWELL_TIME)) +
  geom_histogram(bins = 50, fill = "darkgreen", alpha = 0.7) +
  labs(title = "Gaze Duration (First Run Dwell Time)", x = "Duration (ms)", y = "Count") +
  theme_minimal() +
  xlim(0, 1500)

p3 <- ggplot(ia_clean, aes(x = word_length_no_punctuation)) +
  geom_bar(fill = "coral", alpha = 0.7) +
  labs(title = "Word Length Distribution", x = "Number of characters", y = "Count") +
  theme_minimal()

p4 <- ggplot(ia_clean, aes(x = log10(wordfreq_frequency + 1))) +
  geom_histogram(bins = 50, fill = "purple", alpha = 0.7) +
  labs(title = "Word Frequency (log10)", x = "Log10(frequency)", y = "Count") +
  theme_minimal()

(p1 + p2) / (p3 + p4)
```

**Interpretation:** The distributions reveal several important patterns:

- **First Fixation Duration** shows a right-skewed distribution centered around 150-250 ms, which is typical for reading fixations
- **Gaze Duration** is also right-skewed but with a longer tail, reflecting cases where readers made multiple fixations on words before moving on
- **Word Length** peaks at 2-4 characters (common function words like "the", "and") with decreasing frequency for longer words
- **Word Frequency** (log-transformed) shows a roughly normal distribution, indicating good coverage across the frequency spectrum

## Check for Missing Data in Key Variables

```{r}
# Missing data summary for key variables
key_vars <- c("IA_FIRST_FIXATION_DURATION", "IA_FIRST_RUN_DWELL_TIME",
              "IA_DWELL_TIME", "word_length_no_punctuation",
              "wordfreq_frequency", "gpt2_surprisal", "Reduced_POS")

missing_summary <- ia_clean %>%
  select(all_of(key_vars)) %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Missing_Count") %>%
  mutate(Missing_Percent = round(Missing_Count / nrow(ia_clean) * 100, 2))

kable(missing_summary, caption = "Missing Data Summary")
```

**Interpretation:** The missing data table shows the percentage of missing values for each key variable. After cleaning, most variables should have minimal missing data. Any remaining missing values in reading measures (FFD, Gaze Duration) typically occur when words were skipped entirely, which is expected behavior in natural reading.

---

# Exploratory Visualizations

## Effect of Word Length on Reading

Word length is one of the most robust predictors of eye movements during reading (Rayner, 1998).

```{r}
# Summarize by word length
word_length_summary <- ia_clean %>%
  filter(word_length_no_punctuation >= 1 & word_length_no_punctuation <= 15) %>%
  group_by(word_length_no_punctuation) %>%
  summarise(
    mean_FFD = mean(IA_FIRST_FIXATION_DURATION, na.rm = TRUE),
    se_FFD = sd(IA_FIRST_FIXATION_DURATION, na.rm = TRUE) / sqrt(n()),
    mean_gaze = mean(IA_FIRST_RUN_DWELL_TIME, na.rm = TRUE),
    se_gaze = sd(IA_FIRST_RUN_DWELL_TIME, na.rm = TRUE) / sqrt(n()),
    skip_rate = mean(IA_SKIP == 1, na.rm = TRUE),
    n = n()
  )

# Plot word length effects
p_length <- ggplot(word_length_summary, aes(x = word_length_no_punctuation)) +
  geom_line(aes(y = mean_FFD), color = "steelblue", size = 1) +
  geom_point(aes(y = mean_FFD), color = "steelblue", size = 2) +
  geom_errorbar(aes(ymin = mean_FFD - se_FFD, ymax = mean_FFD + se_FFD),
                width = 0.2, color = "steelblue") +
  labs(title = "Word Length Effect on First Fixation Duration",
       x = "Word Length (characters)", y = "Mean First Fixation Duration (ms)") +
  theme_minimal() +
  scale_x_continuous(breaks = 1:15)

p_skip <- ggplot(word_length_summary, aes(x = word_length_no_punctuation, y = skip_rate)) +
  geom_line(color = "coral", size = 1) +
  geom_point(color = "coral", size = 2) +
  labs(title = "Word Length Effect on Skipping Rate",
       x = "Word Length (characters)", y = "Probability of Skipping") +
  theme_minimal() +
  scale_x_continuous(breaks = 1:15) +
  scale_y_continuous(labels = percent)

p_length / p_skip
```

**Interpretation:** These plots demonstrate the classic **word length effect** in reading:

- **Top panel (First Fixation Duration):** There is a modest positive relationship between word length and fixation duration. Longer words tend to receive slightly longer first fixations, though the effect is relatively small for first fixation duration (typically 5-10 ms per character).

- **Bottom panel (Skipping Rate):** The skipping rate shows a clear negative relationship with word length. Short words (1-3 characters) are skipped approximately 35-45% of the time, while longer words (10+ characters) are rarely skipped (<20%). This reflects the parafoveal preview benefit—readers can often identify short words before directly fixating them.

## Effect of Word Frequency on Reading

High-frequency words are processed faster and skipped more often (Inhoff & Rayner, 1986).

```{r}
# Create frequency bins
ia_clean <- ia_clean %>%
  mutate(freq_bin = cut(log10(wordfreq_frequency + 1e-10),
                        breaks = 5, labels = c("Very Low", "Low", "Medium", "High", "Very High")))

# Summarize by frequency
freq_summary <- ia_clean %>%
  filter(!is.na(freq_bin)) %>%
  group_by(freq_bin) %>%
  summarise(
    mean_FFD = mean(IA_FIRST_FIXATION_DURATION, na.rm = TRUE),
    se_FFD = sd(IA_FIRST_FIXATION_DURATION, na.rm = TRUE) / sqrt(n()),
    mean_gaze = mean(IA_FIRST_RUN_DWELL_TIME, na.rm = TRUE),
    skip_rate = mean(IA_SKIP == 1, na.rm = TRUE),
    n = n()
  )

# Plot frequency effects
ggplot(freq_summary, aes(x = freq_bin, y = mean_FFD)) +
  geom_col(fill = "steelblue", alpha = 0.7) +
  geom_errorbar(aes(ymin = mean_FFD - se_FFD, ymax = mean_FFD + se_FFD),
                width = 0.2) +
  labs(title = "Word Frequency Effect on First Fixation Duration",
       x = "Word Frequency (binned)", y = "Mean First Fixation Duration (ms)") +
  theme_minimal()
```

**Interpretation:** The frequency effect shows that **high-frequency words are processed faster** than low-frequency words. Words in the "Very High" frequency bin receive shorter first fixations compared to words in the "Very Low" bin. This effect reflects the fact that common words have stronger lexical representations, allowing faster word recognition. The frequency effect is one of the most robust findings in reading research and has been replicated across many languages and experimental paradigms.

---

# Main Analysis: Word Length × Frequency Interaction

The exploratory visualizations above reveal robust effects of word length, frequency, predictability, and part of speech on reading behavior. A natural question arises: **do these effects operate independently, or do they interact?**

This section investigates the interaction between word length and word frequency—two of the most fundamental predictors of eye movements during reading.

## Research Question

**Does the effect of word length on fixation duration differ for high-frequency vs. low-frequency words?**

### Background

Both word length and word frequency are well-established predictors of eye movements during reading:

- **Word length effect**: Longer words receive longer fixations and are less likely to be skipped (Rayner, 1998)
- **Frequency effect**: High-frequency words are processed faster and skipped more often (Inhoff & Rayner, 1986)

However, these effects may interact. One hypothesis is that readers can recognize short, high-frequency words rapidly through holistic pattern recognition, while longer and less frequent words require more serial, letter-by-letter processing. This predicts:

> **Hypothesis**: The word length effect should be *stronger* for low-frequency words than for high-frequency words.

## Create Analysis Variables

```{r}
# Create median split for frequency (high vs low)
freq_median <- median(ia_clean$wordfreq_frequency, na.rm = TRUE)

ia_analysis <- ia_clean %>%
  filter(word_length_no_punctuation >= 2 & word_length_no_punctuation <= 12) %>%
  mutate(
    freq_group = ifelse(wordfreq_frequency >= freq_median, "High Frequency", "Low Frequency"),
    freq_group = factor(freq_group, levels = c("Low Frequency", "High Frequency"))
  ) %>%
  filter(!is.na(freq_group))

# Check group sizes
cat("Observations per frequency group:\n")
table(ia_analysis$freq_group)
```

**Interpretation:** The median split creates two roughly equal-sized groups: Low Frequency and High Frequency words. Having balanced group sizes ensures that our statistical comparisons have adequate power and that differences between groups are not driven by unequal sample sizes. Words with lengths 2-12 characters are included to focus on the range where most meaningful variation occurs.

## Visualization: Interaction Plot

```{r}
# Summary by word length and frequency group (for plotting)
interaction_summary <- ia_analysis %>%
  group_by(word_length_no_punctuation, freq_group) %>%
  summarise(
    mean_FFD = mean(IA_FIRST_FIXATION_DURATION, na.rm = TRUE),
    se_FFD = sd(IA_FIRST_FIXATION_DURATION, na.rm = TRUE) / sqrt(n()),
    mean_gaze = mean(IA_FIRST_RUN_DWELL_TIME, na.rm = TRUE),
    se_gaze = sd(IA_FIRST_RUN_DWELL_TIME, na.rm = TRUE) / sqrt(n()),
    n = n(),
    .groups = "drop"
  )
```

```{r fig.width=12, fig.height=5}
# First Fixation Duration interaction plot
p_ffd_interaction <- ggplot(interaction_summary,
                             aes(x = word_length_no_punctuation, y = mean_FFD,
                                 color = freq_group, group = freq_group)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_FFD - se_FFD, ymax = mean_FFD + se_FFD),
                width = 0.2, linewidth = 0.8) +
  scale_color_manual(values = c("Low Frequency" = "#E41A1C", "High Frequency" = "#377EB8")) +
  labs(
    title = "Word Length × Frequency Interaction on First Fixation Duration",
    subtitle = "Error bars represent ±1 SE",
    x = "Word Length (characters)",
    y = "Mean First Fixation Duration (ms)",
    color = "Frequency Group"
  ) +
  theme_minimal(base_size = 12) +
  theme(legend.position = "bottom") +
  scale_x_continuous(breaks = 2:12)

# Gaze Duration interaction plot
p_gaze_interaction <- ggplot(interaction_summary,
                              aes(x = word_length_no_punctuation, y = mean_gaze,
                                  color = freq_group, group = freq_group)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_gaze - se_gaze, ymax = mean_gaze + se_gaze),
                width = 0.2, linewidth = 0.8) +
  scale_color_manual(values = c("Low Frequency" = "#E41A1C", "High Frequency" = "#377EB8")) +
  labs(
    title = "Word Length × Frequency Interaction on Gaze Duration",
    subtitle = "Error bars represent ±1 SE",
    x = "Word Length (characters)",
    y = "Mean Gaze Duration (ms)",
    color = "Frequency Group"
  ) +
  theme_minimal(base_size = 12) +
  theme(legend.position = "bottom") +
  scale_x_continuous(breaks = 2:12)

p_ffd_interaction + p_gaze_interaction
```

**Interpretation:** The interaction plots reveal the central finding of this analysis:

- **Left panel (First Fixation Duration):** The lines for Low Frequency (red) and High Frequency (blue) words show different slopes. Low-frequency words show a steeper increase in fixation duration as word length increases, while high-frequency words remain relatively flat. This suggests that **word length matters more for unfamiliar words**.

- **Right panel (Gaze Duration):** Both frequency groups show positive slopes (longer words receive more total viewing time), but the pattern is similar—low-frequency words show a steeper increase with length.

- **Non-parallel lines** indicate an interaction effect: the magnitude of the word length effect depends on word frequency. This visual pattern will be tested statistically in the regression analysis.

## Statistical Analysis: Linear Regression

We test the interaction using linear regression with word length, frequency, and their interaction as predictors.

```{r}
# Center predictors for interpretable coefficients
ia_analysis <- ia_analysis %>%
  mutate(
    length_centered = word_length_no_punctuation - mean(word_length_no_punctuation),
    freq_centered = wordfreq_frequency - mean(wordfreq_frequency, na.rm = TRUE)
  )

# Fit regression model for First Fixation Duration
model_ffd <- lm(IA_FIRST_FIXATION_DURATION ~ length_centered * freq_centered,
                data = ia_analysis)

cat("=== First Fixation Duration Model ===\n")
summary(model_ffd)
```

**Interpretation of FFD Regression:**

- **Intercept (~199 ms):** The predicted first fixation duration for a word of average length and average frequency
- **length_centered:** The main effect of word length. A non-significant or small positive coefficient suggests word length has minimal effect on FFD when averaged across frequency levels
- **freq_centered:** The main effect of frequency. A positive coefficient indicates that higher frequency words actually have slightly longer FFD (counterintuitive, but may reflect confounds)
- **length_centered:freq_centered (INTERACTION):** This is the key test. A **negative coefficient** indicates that the word length effect is *weaker* for higher-frequency words, supporting our hypothesis. The p-value tells us whether this interaction is statistically significant.

```{r}
# Fit regression model for Gaze Duration
model_gaze <- lm(IA_FIRST_RUN_DWELL_TIME ~ length_centered * freq_centered,
                 data = ia_analysis)

cat("=== Gaze Duration Model ===\n")
summary(model_gaze)
```

**Interpretation of Gaze Duration Regression:**

- **Intercept (~260 ms):** Gaze duration is longer than FFD because it includes all fixations made on a word before the eyes move forward
- **length_centered:** A positive coefficient indicates longer words receive more total viewing time (expected, as longer words often require refixations)
- **freq_centered:** The frequency effect on gaze duration
- **length_centered:freq_centered (INTERACTION):** Tests whether the word length effect on gaze duration differs by frequency. The direction and significance of this coefficient tells us whether the interaction pattern holds for this later measure of processing.


---

# Discussion 

This analysis explored the interaction between word length and word frequency on eye movements during reading using the OneStop Eye Movements Dataset. Both word length and word frequency significantly predict fixation durations, consistent with decades of reading research. The interaction between word length and frequency was statistically significant, revealing that the effect of word length on fixation duration depends on word frequency. Additionally, the word length effect (longer words → longer fixations) is stronger for low-frequency words than for high-frequency words. This suggests that (1) High-frequency words may be recognized more holistically, reducing sensitivity to word length and (2) Low-frequency words require more analytical processing that scales with the number of letters

However, there is some limitations. First, this portfolio used aggregated data; a more rigorous analysis would use mixed-effects models to account for participant and item random effects
- Word length and frequency are correlated, which could complicate interpretation
- The frequency measure used is corpus-based and may not perfectly reflect individual readers' experience
